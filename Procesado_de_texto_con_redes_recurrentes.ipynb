{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Procesado de texto con redes recurrentes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgKcJgj97Rxa4oUQzJ/zfW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalebsampaco/Ejercicios-en-google-colab/blob/master/Procesado_de_texto_con_redes_recurrentes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS0ZJD5QY55K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "436c8bbf-d31d-4c5c-b5c5-ca3e52f7811e"
      },
      "source": [
        "import sys\n",
        "import json\n",
        "import codecs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM,Input,Bidirectional,GlobalMaxPool1D,Flatten,BatchNormalization,LeakyReLU\n",
        "from keras.layers.convolutional import Conv1D,Conv2D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence,text\n",
        "from keras import Model\n",
        "from keras.models import load_model\n",
        "from keras.datasets import imdb\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "#Variables de entrada\n",
        "batch_size = 32\n",
        "epochs = 30\n",
        "tamano_embedding = 128\n",
        "maximas_caracteristicas=20000\n",
        "maxima_longitud=80\n",
        "\n",
        "#Cargado de bases  de datos\n",
        "(xentrenamiento,yentrenamiento),(xtest,ytest)=imdb.load_data(num_words=maximas_caracteristicas)\n",
        "xentrenamiento=sequence.pad_sequences(xentrenamiento,maxlen=maxima_longitud)\n",
        "xtest=sequence.pad_sequences(xtest,maxlen=maxima_longitud)\n",
        "\n",
        "#Creacion de modelo\n",
        "entrada = Input(shape=(maxima_longitud, ))\n",
        "x = Embedding(maximas_caracteristicas, tamano_embedding)(entrada)\n",
        "x = LSTM(tamano_embedding, return_sequences=True,activation='relu')(x)\n",
        "x=Flatten()(x)\n",
        "x = Dense(1, activation=\"sigmoid\",kernel_initializer='zeros',bias_initializer='zeros')(x)\n",
        "modelo = Model(inputs=entrada, outputs=x)\n",
        "modelo.compile(loss='binary_crossentropy',optimizer='adam',metrics=['binary_accuracy'])\n",
        "modelo.summary()\n",
        "\n",
        "\n",
        "#entrenamiento\n",
        "checkpoint = ModelCheckpoint('deteccion_texto.h5', monitor='val_binary_accuracy', verbose=1, save_best_only=True,save_weights_only=False, mode='auto')\n",
        "history=modelo.fit(xentrenamiento, yentrenamiento, batch_size=batch_size, epochs=5, callbacks=[checkpoint],validation_data=(xtest,ytest), shuffle=True, verbose=1)\n",
        "\n",
        "#visualizacion de resultaoos\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Perdidas del Modelo')\n",
        "plt.ylabel('Perdidas')\n",
        "plt.xlabel('Epocas')\n",
        "plt.legend(['Test','Entrenamiento'], loc='upper left')\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(history.history['val_binary_accuracy'])\n",
        "plt.plot(history.history['binary_accuracy'])\n",
        "plt.title('Precision del Modelo')\n",
        "plt.ylabel('Precision')\n",
        "plt.xlabel('Epocas')\n",
        "plt.legend(['Test','Entrenamiento'], loc='upper left')\n",
        "\n",
        "salida=modelo.predict(xentrenamiento[round(len(xentrenamiento[:,0])*0.9):round(len(xentrenamiento[:,0])),:])\n",
        "\n",
        "salida[salida<0.5]=0\n",
        "salida[salida>=0.5]=1\n",
        "\n",
        "diferencia=abs(yentrenamiento[round(len(xentrenamiento[:,0])*0.9):round(len(xentrenamiento[:,0]))]-np.uint8(salida[:,0]))\n",
        "puntos=diferencia[diferencia>0]\n",
        "score=(1-(len(puntos)/len(diferencia)))\n",
        "\n",
        "print('La mejor puntuacion es %f'% (score))\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 80, 128)           2560000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 80, 128)           131584    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10240)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 10241     \n",
            "=================================================================\n",
            "Total params: 2,701,825\n",
            "Trainable params: 2,701,825\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/5\n",
            "   96/25000 [..............................] - ETA: 4:28 - loss: 0.6943 - binary_accuracy: 0.4896"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}