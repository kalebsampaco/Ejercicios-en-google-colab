{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolución cifar100 con imagenes de historial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNe34jcOhtDzbiyhTqD6Dvi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalebsampaco/Ejercicios-en-google-colab/blob/master/convoluci%C3%B3n_cifar100_con_imagenes_de_historial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5H0_gxZpX8C",
        "colab_type": "code",
        "outputId": "4ae0a3d4-0249-430c-dd93-31ff5f6659fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import cifar100\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D,Input\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.optimizers import SGD,Adam\n",
        "from keras.applications import VGG16\n",
        "import matplotlib as plt\n",
        "\n",
        "batch_size=100\n",
        "num_classes=100\n",
        "epochs=5\n",
        "\n",
        "\n",
        "(xt,yt),(xtest,ytest)= cifar100.load_data()\n",
        "\n",
        "_,filas, columnas, canales = xt.shape\n",
        "\n",
        "xt=xt.astype('float32')\n",
        "xtest=xtest.astype('float32')\n",
        "\n",
        "xt=xt/255\n",
        "xtest=xtest/255\n",
        "\n",
        "yt=keras.utils.to_categorical(yt,num_classes)\n",
        "ytest=keras.utils.to_categorical(ytest,num_classes)\n",
        "\n",
        "Entradas=Input(shape=(filas,columnas,canales))\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(Entradas)\n",
        "#x=Dropout(0.25)(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "x = MaxPooling2D((2, 2), name='block1_pool')(x)\n",
        " \n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "#x=Dropout(0.25)(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "x = MaxPooling2D((2, 2), name='block2_pool')(x)\n",
        "\n",
        "x=Flatten()(x)\n",
        "x=Dense(512,activation='relu')(x)\n",
        "x=Dropout(0.5)(x)\n",
        "x=Dense(num_classes,activation='softmax')(x)\n",
        "\n",
        "modelo = Model(inputs=Entradas, outputs=x)\n",
        "#modelo.summary()\n",
        "Adam = Adam(lr=0.001,beta_1=0.9,beta_2=0.9)#SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "modelo.compile(loss=keras.losses.categorical_crossentropy,optimizer=Adam,metrics=['categorical_accuracy'])\n",
        "\n",
        "history = modelo.fit(xt,yt,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(xtest,ytest))\n",
        "\n",
        "puntuacion=modelo.evaluate(xtest,ytest,verbose=1)\n",
        "\n",
        "print(puntuacion)\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(history.history['categorical_accuracy'])\n",
        "plt.plot(history.history['val_categorical_accuracy'])\n",
        "plt.title('Precisión del modelo')\n",
        "plt.ylabel('Presición')\n",
        "plt.xlabel('Epocas')\n",
        "plt.legend(['Entrenamiento', 'Test'], loc='upper left')\n",
        "\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Perdidas del modelo')\n",
        "plt.ylabel('Perdidas')\n",
        "plt.xlabel('Epocas')\n",
        "plt.legend(['Entrenamiento', 'Test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 11s 0us/step\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "24600/50000 [=============>................] - ETA: 5:52 - loss: 4.2937 - categorical_accuracy: 0.0476"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOO5cyZiqyEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}